---
language: "he"
title: "מה זה בעצם Inference Benchmarking - ולמה זה כל כך חשוב?"
categories:
  - "מדידת הסקה"
tags:
  -  "ביצועים"
  - "Throughput"
  - "Latency"
previousPost: "docker-cicd-benchmarking"
nextPost: "inference-engines"
slug: "inference-benchmarking"
---


# מה זה בעצם Inference Benchmarking - ולמה זה כל כך חשוב?

לפני שנצלול לעומק עם Docker, Containers וכלים למדידת ביצועים -
צריך להבין מה בדיוק אנחנו מודדים, ולמה זה קריטי.

## מה זה Inference?

בינה מלאכותית מורכבת משני שלבים עיקריים:

- **Training** - שלב הלמידה, שבו המודל “מבין את העולם”.
- **Inference** - שלב השימוש, שבו הוא מקבל קלט ומחזיר תוצאה.

לדוגמה: מודל שמזהה תמונה של חתול -
ב-training הוא לומד מה זה חתול,
וב-inference הוא רואה תמונה חדשה ומחזיר “זה חתול”.

## אז מה זה Benchmarking?

Benchmarking זה תהליך שבו בודקים ובוחנים את הביצועים של מערכת - במקרה שלנו, של מודל בזמן inference.
זה כולל מדדים כמו:

- **Latency** - כמה זמן לוקח למודל להחזיר תשובה?
- **Throughput** - כמה דגימות לשנייה הוא יכול לעבד?
- **יעילות משאבים** - כמה CPU, GPU וזיכרון נצרכים כדי להגיע לתוצאה הזו?

## למה זה חשוב?

בעולם האמיתי, מודל לא חי בתוך Jupyter Notebook.
הוא רץ על שרת אמיתי, צריך לענות בזמן אמת למשתמשים,
ולעמוד בעומסים משתנים - בלי לשרוף משאבים יקרים.

בלי Benchmarking מדויק:

- אי-אפשר לדעת אם שדרוג שיפר או הרע את הביצועים,
- קשה לבחור את מנוע ה-inference או החומרה המתאימה,
- והכי חשוב - קשה לשחזר תוצאות באופן אמין.

## לסיכום

Benchmarking לא נועד רק למדוד מהירות. הוא נועד לבנות אמון - לדעת שהמודל, התשתית והאופטימיזציה עובדים יחד בהרמוניה. זו אבן היסוד לכל מערכת AI יעילה בקנה מידה אמיתי.
