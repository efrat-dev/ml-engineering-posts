---
language: "he"
title: "איך בונים סביבת Benchmarking עם Docker (כולל GPU)"
categories:
  - "תשתיות"
tags:
  - "Docker"
  - "ביצועים"
series: "Docker למדידת ביצועים"
previousPost: "2-docker-images-containers"
nextPost: "4-docker-inference-benchmarking"
slug: "3-docker-benchmarking-setup"
---


# איך בונים סביבת Benchmarking עם Docker (כולל GPU)

אם בפוסט הקודם דיברנו על למה Docker חשוב למדידה הוגנת,
עכשיו נבין איך בפועל משתמשים בו כדי להריץ benchmark אמין ומהיר למודלים.

## שלב 1: יצירת סביבת Docker עקבית

נניח שאת רוצה למדוד ביצועים של שני מנועי inference שונים (למשל ONNX Runtime ו-TensorRT).
במקום להתקין כל אחד מהם ידנית, יוצרים עבור כל אחד Docker image משלו,
שבו מוגדרות בדיוק התלויות והגרסאות הדרושות.

למשל:

- גרסה מסוימת של CUDA (כדי לוודא תאימות ל-GPU)
- גרסה מדויקת של Python והספריות
- סקריפט ההרצה והמדידה שלך

כך, כל מודל וכל מנוע רצים בתנאים זהים.

## שלב 2: חיבור ה-GPU לתוך הקונטיינר

כדי למדוד ביצועים אמיתיים - חייבים שה-Docker container ייגש ישירות ל-GPU.
לשם כך משתמשים ב-NVIDIA Docker (או nvidia-container-runtime),
שמוסיף שכבת גישה לחומרה מתוך הקונטיינר.

המשמעות: הקוד בתוך הקונטיינר “רואה” את ה-GPU כאילו הוא חלק ממנו,
אבל עדיין נשמרת בידודיות מלאה מהמערכת.

## שלב 3: הרצה מדויקת של benchmark

עכשיו אפשר להריץ את המדידות:
כל ניסוי רץ באותו container, עם אותם תנאים, רק עם שינוי אחד -
למשל גרסת מנוע אחרת, גודל batch שונה, או precision שונה (FP16 לעומת INT8).

Docker מאפשר להריץ את הכול באופן מבוקר, ולשמור את כל הנתונים להשוואה חוזרת.

## למה זה קריטי?

- **שחזוריות מלאה** - אפשר להריץ שוב את אותו ניסוי בעוד חודש ולקבל בדיוק אותה תוצאה.
- **ניידות** - המעבדה שלך יכולה להעביר את אותו container לצוות אחר,
  והם יקבלו בדיוק את אותה סביבת בדיקה.
- **אמינות** - שום גורם חיצוני (כמו דרייברים או גרסת מערכת) לא ישפיע על התוצאה.

## לסיכום

Docker הופך benchmarking מ”ניסוי במחשב שלי” ל-מדע מדויק.
כשמוסיפים לו תמיכה ב-GPU, הוא מאפשר לבדוק בצורה הוגנת באמת
איזה מנוע או מודל מביא את הביצועים הכי טובים -
בלי רעש, בלי הפתעות, ועם אמון מלא בתוצאה.
