---
language: "he"
title: "Divided Resources - איך מחלקים משאבים בין מודלים או תהליכים"
categories:
  - "למידת מכונה"
  - "חומרה"
tags:
  - "חלוקת משאבים"
  - "אופטימיזציה"
  - "הסקה"
series: "אופטימיזציה של חומרת הסקה"
previousPost: "6-thread-affinity"
nextPost: "8-resource-optimization"
slug: "7-resource-division"
---


# Divided Resources - איך מחלקים משאבים בין מודלים או תהליכים

במערכת אחת יכולים לרוץ כמה מודלים או שירותי inference במקביל - כל אחד דורש CPU, GPU, זיכרון, ורוחב פס.
השאלה היא: איך מחלקים את המשאבים כך שהמערכת כולה תישאר יעילה?

## למה זה מורכב?

במערכת יחידה, המשאבים לא אינסופיים.
אם נותנים למודל אחד יותר מדי כוח חישוב, האחרים יתחילו להמתין - מה שיוביל ל-latency גבוה ו-throughput נמוך.
אם מחלקים שווה בשווה, כולם יקבלו "מעט מדי" - והמערכת לא תנצל את מלוא הפוטנציאל.

## ה-Trade-off הקלאסי: Throughput מול Latency

- **Throughput גבוה** - כמה תחזיות (inferences) המערכת מצליחה לעבד בשנייה.
  מושג חשוב כשיש עומס גדול של בקשות.
- **Latency נמוך** - כמה זמן לוקח לבקשה אחת להסתיים.
  קריטי כשיש צורך בתגובה מיידית (כמו במערכות זמן אמת).

ככל שמעמיסים יותר תהליכים במקביל, ה-throughput עולה - אבל ה-latency של כל תהליך מתארך.
זו מערכת של איזונים עדינים, לא “כמה שיותר זה יותר טוב”.

## שתי גישות עיקריות לניהול עומסים

1. **Load Balancing**
   גישה שמחלקת בקשות באופן דינמי בין מודלים או תהליכים שונים.
   מתאימה כשכל התהליכים שווי ערך, והמטרה היא לשמור על ניצול מאוזן.

   דוגמה: שרת inference שמאזן בין כמה רפליקות של אותו מודל.
   - **היתרון** - גמישות ועמידות.
   - **החיסרון** - פחות שליטה על אילו משאבים כל תהליך באמת צורך.

2. **Resource Isolation**
   במקום לאזן “תוך כדי תנועה”, מגדירים מראש גבולות ברורים:
   איזה מודל רץ על אילו ליבות, כמה זיכרון הוא מקבל, ואיזה GPU הוא רשאי להשתמש בו.

   זו גישה שמאפשרת יציבות וביצועים צפויים - במיוחד כשיש מודלים קריטיים שאסור שיפגעו מתחרות.

## איך קונפיגורציה חכמה משנה הכול

מערכת שמגדירה נכון:

- כמה threads מוקצים לכל מודל,
- כמה בקשות במקביל מותר לו לעבד,
- ואיך הוא חולק משאבים עם אחרים,

יכולה לשפר ביצועים בעשרות אחוזים - בלי לשנות שורת קוד אחת במודל עצמו.

## בשורה התחתונה

חלוקת משאבים זה לא רק עניין של “כמה כוח יש”, אלא איך משתמשים בו.
ניהול נכון של משאבים בין מודלים ותהליכים הוא אחד הכלים החשובים ביותר באופטימיזציית inference:
איזון מדויק בין throughput ל-latency, שמבדיל בין מערכת שמקרטעת - למערכת שמרגישה כמו מנוע מכויל היטב.