---
language: "he"
title: "סיכום הסדרה: מ-NUMA ועד Throughput - איך אופטימיזציה הופכת חומרה לביצועים"
categories:
  - "למידת מכונה"
  - "חומרה"
tags:
  - "אופטימיזציה"
  - "NUMA"
  - "הצמדת תהליכים"
  - "ניהול משאבים"
series: "אופטימיזציה של חומרת הסקה"
previousPost: "8-resource-optimization"
slug: "9-series-summary"
---


# סיכום הסדרה: מ-NUMA ועד Throughput - איך אופטימיזציה הופכת חומרה לביצועים

במהלך הסדרה הזו ראינו שהביצועים של מערכת Inference לא נובעים רק מהמודל -
אלא מהאופן שבו המערכת כולה בנויה סביבו.

## למדנו על:

- **NUMA** - למה קרבת זיכרון משפיעה על latency,
  ואיך גישה לזיכרון “מרוחק” יכולה להאט מערכת שלמה.
- **חלוקת ליבות ו-Thread Affinity** -
  איך קיבוע threads לליבות הנכונות מונע איבוד cache ומעלה יעילות.
- **Resource Division** -
  איך תכנון נכון של חלוקת משאבים בין מודלים שומר על איזון בין throughput ו-latency.
- **Scaling חכם** -
  מתי הגדלת כמות התהליכים עוזרת, ומתי היא רק יוצרת עומס.

ולבסוף, ראינו דוגמת מקרה אמיתית שבה שינוי ארכיטקטוני בלבד
הביא לשיפור פי שלושה בביצועים - בלי לשנות שורת קוד אחת במודל עצמו.

## המסר המרכזי

ב-Inference Optimization אין קסמים.
כל שיפור אמיתי מגיע מהבנה של מה מתרחש “מתחת למכסה המנוע” -
איך המעבד ניגש לזיכרון, איך תהליכים מתוזמנים, ואיך עומס מחולק.

מערכת מהירה באמת היא לא זו שיש לה הכי הרבה ליבות -
אלא זו שמנצלת כל אחת מהן בצורה חכמה.

## ומה הלאה?

בסדרת ההמשך ניכנס לשלב המעשי:
נראה איך להריץ Benchmark חכם שמודד את כל ההשפעות האלו בפועל.

### נלמד:

- איך למדוד Latency ו-Throughput בצורה אמינה.
- איך לזהות Bottlenecks אמיתיים בעזרת נתוני CPU, NUMA ו-Memory Access.
- ואיך להוכיח במספרים מה השתנה אחרי כל אופטימיזציה.

## בשורה התחתונה

אופטימיזציה לא נמדדת בתחושה - היא נמדדת ב-Data.
כדי להבין באמת את ההשפעות של NUMA, חלוקת ליבות או Scaling,
צריך לראות אותן במספרים, בזמן אמת.

זה בדיוק מה שנעשה בפרק הבא -
נבנה את ה-Benchmark שמראה איך תיאוריה הופכת לביצועים.