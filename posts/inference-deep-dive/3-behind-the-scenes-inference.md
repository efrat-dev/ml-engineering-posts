---
language: "he"
title: "מה קורה מאחורי הקלעים כשהמודל עונה לך? (Prefill, Decoding ו-KV Cache)"
categories:
  - "הסקה"
tags:
  - "Prefill"
  - "Decode"
  - "KV Cache"
series: "מסע אל עולם ההסקה"
previousPost: "2-how-inference-works"
nextPost: "4-bottlenecks-in-inference"
slug: "3-behind-the-scenes-inference"
---


# מה קורה מאחורי הקלעים כשהמודל עונה לך? (Prefill, Decode ו-KV Cache)

כשאת שולחת שאלה למודל שפה, זה נראה כאילו הוא פשוט "ממציא" תשובה ברצף -
אבל בפועל, יש שני שלבים עיקריים בתהליך שנקרא Inference:

## שלב 1: Prefill

בשלב הזה המודל מקבל את כל הקלט שלך (ה-prompt) ומחשב את הייצוג הפנימי שלו.
זה כמו שמישהו קורא את כל השאלה שלך לפני שהוא מתחיל לענות.
בשלב הזה מתבצעים חישובים רבים - אבל הוא קורה רק פעם אחת לכל שאלה.

## שלב 2: Decode

עכשיו מתחילה היצירה בפועל - המודל מייצר כל טוקן חדש, אחד אחרי השני.
כל טוקן תלוי במה שנוצר לפניו, ולכן נדרש לזכור את ההיסטוריה.

## KV Cache

זהו מעין "פנקס זיכרון" שבו נשמרים תוצאות ביניים של השכבות הפנימיות.
במקום לחשב הכול מחדש בכל פעם - המודל פשוט שומר את מה שכבר עבד עליו.

- היתרון: חיסכון משמעותי בזמן ובחישוב.
- האתגר: ככל שהתשובה מתארכת, גם ה-cache גדל ותופס יותר זיכרון.
  אם הגישה אליו איטית - זה עצמו הופך לצוואר בקבוק.

## למה זה חשוב?

ניהול נכון של KV Cache הוא אחד המפתחות להאצת inference במודלים גדולים.
חברות חומרה ותוכנה משקיעות מאמצים עצומים באופטימיזציה שלו -
כי הוא משפיע ישירות על throughput (כמה טוקנים לשנייה ניתן להפיק).

---

**בפוסט הבא נלמד על:** צווארי בקבוק (Bottlenecks) שיכולים להאט את תהליך ה-Inference - מזיכרון ועד תזמון, ואיך לזהות אותם.
