---
language: "he"
title: "איך מגדילים תפוקה בלי להאט את המערכת? (Batching, Stream Scheduling ו-Offload)"
categories:
  - "אופטימיזציית הסקה"
tags:
  - "ביצועים"
  - "Throughput"
previousPost: "behind-the-scenes-inference"
nextPost: "how-inference-works"
slug: "increasing-throughput"
---


# איך מגדילים תפוקה בלי להאט את המערכת? (Batching, Stream Scheduling ו-Offload)

כשאלפי משתמשים שולחים בקשות למודל באותו זמן - איך הוא מספיק לענות לכולם?
כאן נכנסים שלושה מנגנונים חכמים שמאפשרים למערכת לעבוד ביעילות מקסימלית.

## Batching - לאחד במקום לעבד בנפרד

במקום שכל בקשה תעבור לבד, כמה בקשות דומות נאספות יחד ל-Batch אחד.
כך המאיץ (GPU או NPU) יכול לחשב את כולן במקביל, מה שחוסך זמן חישוב יקר.

Continuous Batching לוקח את זה צעד קדימה -
אין יותר המתנה שיתמלא batch חדש, אלא זרימה רציפה של בקשות.
המאיץ תמיד עסוק, ה-throughput עולה, וה-idle time יורד כמעט לאפס.

## Stream Scheduling - לנצל כל רגע חישובי

לא כל הבקשות זהות באורך שלהן או במורכבותן.
לכן נדרש מתזמן (scheduler) שמחליט מי ירוץ מתי ובאיזה סדר.

אם הוא יעשה זאת נכון -
המאיץ יעבוד במקביל על כמה “זרמים” (streams) בלי לבזבז משאבים.
אם לא - בקשות קצרות יחכו לזרם ארוך ויסבלו מעיכוב מיותר.

## Offload - להעביר עומס לחומרה חכמה

במערכת רגילה, ה-CPU מנהל את כל הבקשות, התורים והעדיפויות.
אבל זה גורם לו להיות צוואר בקבוק.
לכן משתמשים ב-offload - העברת חלק מהניהול לחומרה ייעודית (כמו מאיץ או AI CPU).

החומרה הזו מטפלת בניהול התקשורת והזרימה בעצמה,
כך שה-CPU מתפנה למשימות אחרות והמערכת כולה מואצת.

## בשורה התחתונה

שלושת המנגנונים האלה פועלים יחד:

- Batching דואג לניצול טוב של המאיץ.
- Stream Scheduling שומר על רציפות חכמה.
- Offload מונע עומס על ה-CPU.

כשמשלבים אותם - המערכת עובדת במהירות וביעילות חסרת תקדים.