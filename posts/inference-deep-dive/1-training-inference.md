---
language: "he"
title: "מהו Inference ולמה הוא קורה אחרי Training?"
categories:
  - "הסקה"
tags:
  - "אימון מודלים"
series: "מסע אל עולם ההסקה"
previousPost: "null"
nextPost: "2-how-inference-works"
slug: "1-training-inference"
---


# מהו Inference ולמה הוא קורה אחרי Training?

כדי להבין את עולם ה-inference, נתחיל מהדימוי הכי פשוט:
דמיינו תלמיד שלומד במשך חודשים למבחן. הוא קורא ספרים, מתאמן על שאלות, מתקן טעויות - זהו שלב ה-training.
אבל ביום המבחן עצמו - הוא כבר לא לומד. הוא רק מיישם את מה שכבר למד.
זה בדיוק מה שקורה במודל בינה מלאכותית.

## שלב 1 - האימון (Training)

בשלב זה המודל לומד מתוך כמויות אדירות של מידע.
הוא משנה את "המשקולות" הפנימיות שלו (ערכים מתמטיים שמייצגים ידע) כדי להתאים בין קלט (input) לפלט נכון (output).
זהו תהליך איטי, כבד, ודורש חומרה ייעודית - GPUs, TPUs או מאיצים יקרים.

## שלב 2 - ההרצה (Inference)

עכשיו, כשהמודל מאומן, מגיע שלב ההפעלה: inference.
במקום ללמוד, הוא רק "מחשב" את התשובה החדשה לפי הידע שכבר יש לו.
זה כמו שהתלמיד במבחן לא קורא ספר - אלא פשוט עונה לפי מה שזוכר.

ב-inference מתבצע חישוב אחד בלבד - ה-forward pass - מעבר קדימה דרך הרשת הנוירונית.
אין עדכון משקולות, אין תיקון טעויות, רק הפקת תשובה.

## אז למה זה חשוב?

כי כל שאלה שאת שואלת את מודל כמו ChatGPT, או כל תמונה שמודל מייצר,
היא בעצם inference אחד.
ולכן היעילות של התהליך הזה קובעת:
- כמה מהר תקבלי תשובה (latency),
- כמה תשובות אפשר להריץ במקביל (throughput),
- וכמה חשמל / חומרה זה יעלה.

## בשורה התחתונה

Training = ללמוד.

Inference = ליישם את מה שנלמד.

מהירות ה-inference היא מה שמאפשרת לעולם ה-AI להפוך לכלי שימושי ולא רק ניסוי במעבדה.

---

**בפוסט הבא נלמד על:** איך תהליך ה-Inference עובד בפועל, מה קורה מאחורי הקלעים כשהמודל מקבל קלט ומחזיר תשובה.
